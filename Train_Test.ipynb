{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40616f6d-5eb0-49a3-a949-5d134061b679",
   "metadata": {},
   "source": [
    "# **Train-Test split** (Improve-Evaluate split)\n",
    "----\n",
    "\n",
    "## Goals of this notebook:\n",
    "\n",
    "1. Discuss the proper sample size to calculate average rewards (main metric).\n",
    "2. Define methods to alternate between train and test mode.\n",
    "3. Parallelize operations to gain some efficiency.\n",
    "---\n",
    "## Library imports\n",
    "\n",
    "#### 1. RL libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1d0cc2-c7ac-4a38-98b0-497db244bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import environments\n",
    "from agents.agents import TDLambdaPredictor, WatkinsLambda, Sarsa,\\\n",
    "                          QLearning, SarsaLambda, MonteCarloPredictor,\\\n",
    "                          MontecarloController, OffPolicyMontecarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3ea1b-79cc-475e-9d6f-b2f9742e3375",
   "metadata": {},
   "source": [
    "#### 2. Data aggregation and matrix operation libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcd437d-663d-4754-941b-2aceea018752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08411b0-82b1-46d9-bb62-2aa04858bee4",
   "metadata": {},
   "source": [
    "#### 3. Plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e126c7d6-7dd8-4ef4-b764-e6c063e2616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.ticker import FormatStrFormatter, ScalarFormatter, FuncFormatter\n",
    "import seaborn as sns\n",
    "# Commands to tweak notebook layout:\n",
    "from sys import maxsize\n",
    "np.set_printoptions(threshold=maxsize)\n",
    "plt.style.use('seaborn-pastel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747238e-58a1-4c74-95b0-deeb9b40c746",
   "metadata": {},
   "source": [
    "#### 4. Statistical analysis tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff03bd2-1d09-4a7b-81b5-1eb37c5e8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import normaltest, anderson, t, kstest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64926b-3ed8-405d-b8c2-515cbf5e4880",
   "metadata": {},
   "source": [
    "#### 5. Parallel programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38e041f-809e-4c0d-a283-0e4d69603e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf2782-a589-4dde-9ac7-8715cdb74020",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Common plotting utilities:\n",
    "\n",
    "#### Average reward time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d849d99-e2e5-4d24-99be-73dde41b0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_time_series(X,Y, far=True):\n",
    "    \"\"\"\n",
    "    X: a range of numbers starting from the sample size number to the total number of episode + 1\n",
    "       (to make it inclusive) and incrementing by sample size steps.\n",
    "    Y: average rewards\n",
    "    far: bool. If False the plots zooms in.\n",
    "    \n",
    "    returns: the plot container instance\n",
    "    \"\"\"\n",
    "    # domain redefinition to adjust how many x-ticks are displayed dinamically\n",
    "    max_domain = X[-1]\n",
    "    multiplier = len(str(max_domain)) - 2\n",
    "    step = int(str(max_domain)[0]) * 10**multiplier\n",
    "    domain = np.arange(X[0], max_domain + step, step)\n",
    "    \n",
    "    if far:\n",
    "        ylim = (-1, 1)\n",
    "        yticks= np.arange(-1,1.05,0.05)\n",
    "    else:\n",
    "        max_value = max(0, max(Y))\n",
    "        ylim = (min(Y), max_value)\n",
    "        yticks = np.arange(min(Y), max_value + 0.01, 0.01)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    style_dict = {'xlim': (X[0], max_domain),\n",
    "                  'xticks': domain,\n",
    "                  'xticklabels': domain,\n",
    "                  'xlabel': 'Episodes',\n",
    "                  'ylim': ylim,\n",
    "                  'yticks': yticks,\n",
    "                  'yticklabels': yticks,\n",
    "                  'title': 'Average reward over last {0:,.0f} episodes'.format(X[0])\n",
    "                 }\n",
    "    \n",
    "    ax = fig.add_subplot(1,1,1, **style_dict)\n",
    "    ax.grid()\n",
    "    #Axis formatters:\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    #Scientific value display when the total number of episodes is over 1M:\n",
    "    formatter.set_scientific(True)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('% 1.2f'))\n",
    "    # in and out of the money border:\n",
    "    ax.plot(domain.ravel(), np.zeros_like(domain).ravel(), color='red')\n",
    "    \n",
    "    ax.plot(X,Y)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718024d0-04ec-4a86-bdb1-b5dbbf3afadc",
   "metadata": {},
   "source": [
    "#### Density plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2397b259-2b2d-4e0a-b921-61a0212480cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density(data):\n",
    "    \"\"\"\n",
    "    data: a Panda Series containing every sample of average rewards\n",
    "    \n",
    "    returns: both histogram and boxplot container instances\n",
    "    \"\"\"\n",
    "    title = 'Average reward sampling: $\\overline{{X}}$={0:.2f}, s={1:.2f}, n={2:,.0f}, num of samples={3:,.0f}'\\\n",
    "            .format(data.mean(),\n",
    "                    data.std(),\n",
    "                    data.index.values[0],\n",
    "                    len(data))\n",
    "    \n",
    "    fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, figsize=(20,10), gridspec_kw={\"height_ratios\": (.15, .85)}) \n",
    "    fig.suptitle(t=title, fontsize=16, x=0.5, y=1.05)\n",
    "    \n",
    "    sns.boxplot(data=data,x=data, ax=ax_box)\n",
    "    sns.histplot(data=data, x=data, ax=ax_hist, bins=20, kde=True)\n",
    "    \n",
    "    #Delimiting tails:\n",
    "    ax_hist.axvline(x=np.percentile(data,[2.5]), label='2.5th percentile', c='r')\n",
    "    ax_hist.axvline(x=np.percentile(data,[97.5]), label='97.5th percentile', c='r')\n",
    "    ax_hist.legend()\n",
    "    ax_hist.set_xlabel('Average Reward')\n",
    "    \n",
    "    return ax_box, ax_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee627aed-eb74-4e8b-bf88-1f2538fe357c",
   "metadata": {},
   "source": [
    "#### Value Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6546cae-c81c-426d-980a-dc2aa753359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_v_func(table, title):\n",
    "    \"\"\"\n",
    "    table: agent's V-table (if agents has a Q-table, it must be transformed before being passed as an argument for this function)\n",
    "    title: str. A title for the plot\n",
    "    \n",
    "    returns: the plot container instance\n",
    "    \"\"\"\n",
    "    X = np.linspace(1,10,10)\n",
    "    Y = np.linspace(12, 20,9)\n",
    "    Xm, Ym = np.meshgrid(X, Y)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fig.suptitle(t=title, fontsize=16, x=0.5, y=1.05)\n",
    "    \n",
    "    common_style_dict = {'xlim': (X[0], X[-1]),\n",
    "                        'xticks': X,\n",
    "                        'xticklabels': ['{:.0f}'.format(value) for value in list(X)[1:]] + ['A'],\n",
    "                        'xlabel': 'Dealer\\'s Card',\n",
    "                        'ylim': (Y[0], Y[-1]),\n",
    "                        'yticks': Y,\n",
    "                        'yticklabels': Y,\n",
    "                         'ylabel': 'Player\\'s Total',\n",
    "                        'zlim': (-1, 1.5),\n",
    "                        'zticks': np.arange(-1, 1.8, 0.2),\n",
    "                        'zticklabels': np.arange(-1, 1.8, 0.2),\n",
    "                        }\n",
    "    \n",
    "    #Not usable ace-related states:\n",
    "    ax = fig.add_subplot(1,2,1, projection='3d', title='No usable Ace', **common_style_dict)\n",
    "    surface_1 = ax.plot_surface(Xm, Ym, table[8:17,:10,0], cmap=plt.get_cmap('bwr'), vmin=-1, vmax=1)\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('% 1.0f'))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('% 1.1f'))\n",
    "    ax.view_init(ax.elev, -120)\n",
    "    \n",
    "    #Usable ace-related states:\n",
    "    ax = fig.add_subplot(1,2,2, projection='3d', title=' Usable Ace', **common_style_dict)\n",
    "    surface_2 = ax.plot_surface(Xm, Ym, table[8:17,:10,1], cmap=plt.get_cmap('bwr'), vmin=-1, vmax=1)\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('% 1.0f'))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('% 1.1f'))\n",
    "    ax.view_init(ax.elev, -120)\n",
    "    \n",
    "    #Colour bar:\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.35, 0.01, 0.5])\n",
    "    fig.colorbar(surface_1,shrink=0.2, aspect=15, cax=cbar_ax)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389bf90-f65b-4a9c-abf2-03832812f73f",
   "metadata": {},
   "source": [
    "#### Policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabc8539-106c-4f7e-b3b2-a61e2d510594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_policy(table, title):\n",
    "    \"\"\"\n",
    "    table: matrix containing action indexes (it must have n-1 dimensions with respect to the agent's Q-table)\n",
    "    title: str. A title for the plot\n",
    "    \n",
    "    returns: the plot container instance\n",
    "    \"\"\"\n",
    "    #tick label transformer (used for the colour bar):\n",
    "    def format_tick(x, pos):\n",
    "        if x == 0:\n",
    "            return '{0}-STAND'.format(str(x))\n",
    "        elif x == 1:\n",
    "            return '{0}-HIT'.format(str(x))\n",
    "    \n",
    "    X = np.arange(-.5,9.5,1)\n",
    "    Y = np.arange(0.5, 11.5,1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fig.suptitle(t=title, fontsize=16, x=0.5, y=1.05)\n",
    "    \n",
    "    common_style_dict = {'xlim': (-.5, 9.5),\n",
    "                        'xticks': X,\n",
    "                        'xticklabels': ['{:.0f}'.format(value) for value in range(2,11,1)] + ['A'],\n",
    "                        'xlabel': 'Dealer\\'s Card',\n",
    "                        'yticks': Y,\n",
    "                        'yticklabels': np.arange(11,22,1),\n",
    "                        'ylabel': 'Player\\'s Total'\n",
    "                        }\n",
    "    #I only plot those states wherein there is risk of going bust after hitting once more and, for the sake of symmetry,\n",
    "    #I manually modify those non-existing usable-ace-related states:\n",
    "    table[:8,:,1] = 1\n",
    "    \n",
    "    #Not usable ace-related states:\n",
    "    ax = fig.add_subplot(1,2,1, title='No usable Ace', **common_style_dict)\n",
    "    im = ax.imshow(table[7:18,:10,0], cmap=plt.get_cmap('bwr'), vmin=0, vmax=1, alpha=0.5)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True,color='w', linestyle='-', linewidth=1, axis='both')\n",
    "    ##Little tweak for tick labels' position:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_horizontalalignment('left')\n",
    "\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_verticalalignment('top')\n",
    "    \n",
    "    #Usable ace-related states:\n",
    "    ax = fig.add_subplot(1,2,2, title=' Usable Ace', **common_style_dict)\n",
    "    ax.imshow(table[7:18,:10,1],cmap=plt.get_cmap('bwr'), vmin=0, vmax=1, alpha=0.5)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True,color='w', linestyle='-', linewidth=1, axis='both')\n",
    "    ##Little tweak for tick labels' position:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_horizontalalignment('left')\n",
    "    \n",
    "    #Colour bar definition\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    original_cmap = plt.get_cmap('bwr')\n",
    "    \n",
    "    #Converting a multiple-colour cmap into 2-colour cmap\n",
    "    cmap = ListedColormap([original_cmap(0), original_cmap(original_cmap.N)])\n",
    "    bounds = [0, 0.5, 1]\n",
    "    norm = BoundaryNorm(bounds, original_cmap.N)    \n",
    "    cbar_ax = fig.add_axes([0.85, 0.05, 0.01, 0.85])\n",
    "    \n",
    "    fig.colorbar(cm.ScalarMappable(cmap=cmap, norm=norm),\n",
    "                 shrink=0.2,\n",
    "                 aspect=15,\n",
    "                 cax=cbar_ax,\n",
    "                 boundaries= [0] + bounds + [2],  \n",
    "                 extend='both',\n",
    "                 ticks=[0,1],\n",
    "                 format = FuncFormatter(format_tick),\n",
    "                 spacing='proportional',\n",
    "                 orientation='vertical',\n",
    "                 alpha= 0.5)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87895b41-ff22-4324-b6ba-3fbc13473f2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Statistical functions:\n",
    "\n",
    "I use an **alpha value of 1%** for any statistical test executed in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ddf5fd-27af-4c6b-83ee-5e844115fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_STRING_FORMAT = '1%'\n",
    "CONFIDENCE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff10b6f-56df-44a4-bf45-52ce60cfbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dickey_fuller(time_series, confidence=CONFIDENCE):\n",
    "    fuller_results = adfuller(time_series)\n",
    "    if fuller_results[1] <= confidence:\n",
    "        return 'Null hypothesis can be rejected. The series is stationary.'\n",
    "    else:\n",
    "        return 'Null hypothesis cannot be rejected. The series is not stationary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78f7c18-92b1-42c4-b1e2-7bc715336a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov(values, val):\n",
    "    standarised = StandardScaler().fit(values.reshape((len(values),1)))\\\n",
    "                                  .transform(values.reshape((len(values),1)))\\\n",
    "                                  .ravel()\n",
    "        \n",
    "    return int(kstest(standarised, t.rvs(val-1,size=len(values))).pvalue > alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b316980-ade0-443e-96a8-f816c4a0f436",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Experiment Definition:\n",
    "\n",
    "#### Montecarlo method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd4e7ad-8898-4607-88e2-e9a4f144a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(environment, agent, episodes, show, save=None, collect_rewards=None, train=True):\n",
    "    \"\"\"\n",
    "    environment: instance of the environment to execute.\n",
    "    agent: instance of the agent that will interact with the environment.\n",
    "    show: integer. It indicates how often episodes are printed as text(it helps track the existence of bugs in the game itself).\n",
    "    save: integer. It indicates how often the V/Q-table is permanently persisted as a pickle object. None = no persistence at all.\n",
    "    collect_rewards: It indicates every so many episodes rewards are averaged. 1 = return every reward.\n",
    "    train: bool. If True, the agent learns by updating its V/Q-table; if False, the agent just executes a defined policy.\n",
    "    \n",
    "    returns: a list containing all average rewards computed throughout the whole experiment.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    average_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        if (episode+1) % show ==0:\n",
    "            print('Episode {0}:'.format(episode+1))\n",
    "            env.render()\n",
    "\n",
    "        state, reward, terminal, _ = env.reset()\n",
    "        while not terminal:\n",
    "            action = agent.follow_policy(state)\n",
    "            next_state, reward, terminal, _ = env.step(action)\n",
    "            if train:\n",
    "                agent.evaluate_state(state, reward, terminal, action)   \n",
    "                \n",
    "            state=next_state\n",
    "            \n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if save:\n",
    "            if (episode+1) % save == 0:\n",
    "                agent.save_table()\n",
    "                \n",
    "        if collect_rewards:\n",
    "            if (episode+1) % collect_rewards == 0:\n",
    "                average_reward = sum(rewards[-collect_rewards:])/collect_rewards\n",
    "                average_rewards.append(average_reward)\n",
    "    \n",
    "    return average_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd5873f4-ed5e-45ac-b3f0-7f0f34e45d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_one_step(env, agent, episodes, show, save=None, collect_rewards=None, train=True):\n",
    "    \"\"\"\n",
    "    environment: instance of the environment to execute.\n",
    "    agent: instance of the agent that will interact with the environment.\n",
    "    show: integer. It indicates how often episodes are printed as text(it helps track the existence of bugs in the game itself).\n",
    "    save: integer. It indicates how often the V/Q-table is permanently persisted as a pickle object. None = no persistence at all.\n",
    "    collect_rewards: It indicates every so many episodes rewards are averaged. 1 = return every reward.\n",
    "    train: bool. If True, the agent learns by updating its V/Q-table; if False, the agent just executes a defined policy.\n",
    "    \n",
    "    returns: a list containing all average rewards computed throughout the whole experiment.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    average_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        if (episode+1) % show ==0:\n",
    "            print('Episode {0}:'.format(episode+1))\n",
    "            env.render()\n",
    "\n",
    "        state, reward, terminal, _ = env.reset()\n",
    "        while not terminal:\n",
    "            action = agent.follow_policy(state)\n",
    "            next_state, reward, terminal, _ = env.step(action)\n",
    "            if train:\n",
    "                agent.evaluate_state(state, reward, terminal, action, next_state)   \n",
    "                \n",
    "            state=next_state\n",
    "            \n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if save:\n",
    "            if (episode+1) % save == 0:\n",
    "                agent.save_table()\n",
    "                \n",
    "        if collect_rewards:\n",
    "            if (episode+1) % collect_rewards == 0:\n",
    "                average_reward = sum(rewards[-collect_rewards:])/collect_rewards\n",
    "                average_rewards.append(average_reward)\n",
    "    \n",
    "    return average_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e54bac99-c754-4e34-b2d9-ee453aa8cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_sarsa(env, agent, episodes, show, save=None, collect_rewards=None, train=True):\n",
    "    \"\"\"\n",
    "    environment: instance of the environment to execute.\n",
    "    agent: instance of the agent that will interact with the environment.\n",
    "    show: integer. It indicates how often episodes are printed as text(it helps track the existence of bugs in the game itself).\n",
    "    save: integer. It indicates how often the V/Q-table is permanently persisted as a pickle object. None = no persistence at all.\n",
    "    collect_rewards: It indicates every so many episodes rewards are averaged. 1 = return every reward.\n",
    "    train: bool. If True, the agent learns by updating its V/Q-table; if False, the agent just executes a defined policy.\n",
    "    \n",
    "    returns: a list containing all average rewards computed throughout the whole experiment.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    average_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        if (episode+1) % show ==0:\n",
    "            print('Episode {0}:'.format(episode+1))\n",
    "            env.render()\n",
    "\n",
    "        state, reward, terminal, _ = env.reset()\n",
    "        next_action = None\n",
    "        while not terminal:\n",
    "            if next_action:\n",
    "                action = next_action\n",
    "            else:\n",
    "                action = agent.follow_policy(state)\n",
    "                \n",
    "            next_state, reward, terminal, _ = env.step(action)\n",
    "            if not terminal:\n",
    "                next_action = agent.follow_policy(next_state)\n",
    "            else:\n",
    "                next_action = None\n",
    "                \n",
    "            if train:\n",
    "                agent.evaluate_state(state, reward, terminal, action, next_state, next_action)   \n",
    "            \n",
    "            state=next_state\n",
    "            \n",
    "        rewards.append(reward)\n",
    "        \n",
    "        if save:\n",
    "            if (episode+1) % save == 0:\n",
    "                agent.save_table()\n",
    "                \n",
    "        if collect_rewards:\n",
    "            if (episode+1) % collect_rewards == 0:\n",
    "                average_reward = sum(rewards[-collect_rewards:])/collect_rewards\n",
    "                average_rewards.append(average_reward)\n",
    "    \n",
    "    return average_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d03fb-4696-4ea9-8dd2-5424f7d6003b",
   "metadata": {},
   "source": [
    "#### Wrapper:\n",
    "\n",
    "So far, I have deployed a total of 7 agents and 3 different experiments. I must admit that this can be somewhat confusing and needs to be untangled. Let's wrap  it all up in an informing dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a78c2142-ca49-4a97-afec-f60a9a5b76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_methods = {'MonteCarloPredictor': run_experiment,\n",
    "                  'MontecarloController': run_experiment,\n",
    "                  'OffPolicyMontecarlo': run_experiment,\n",
    "                  'TDLambdaPredictor': run_experiment_one_step,\n",
    "                  'WatkinsLambda': run_experiment_sarsa,\n",
    "                  'Sarsa': run_experiment_sarsa,\n",
    "                  'QLearning': run_experiment_one_step,\n",
    "                  'SarsaLambda': run_experiment_sarsa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b987d4d8-ec13-4e83-a4c6-a8fc9646c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.run_experiment(environment, agent, episodes, show, save=None, collect_rewards=None, train=True)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents_methods['MonteCarloPredictor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30df195-dba8-4f32-be82-2c84bf07b2d6",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## On Sample Size (to evaluate policies):\n",
    "\n",
    "So far, I have just used an arbitrary number to decide how often rewards should be averaged. However, it would be nice to find a good balance between finding a good estimation of the real value of a policy and execution time.\n",
    "\n",
    "It seems obvious that the larger the sample size, the lower the standard deviation. So, I will empirically assess how standard deviation behaves when enlarging the sample size and then decide the sample size I will use for future experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faa4ef0e-748a-4d0d-84fa-bf7caf8497c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an environment instance:\n",
    "env = environments.make('hitstand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2260e9e2-f97d-417b-851c-b4e634de34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an agent that uses an arbitrary policy to play (policy is not important for the problem at hand)\n",
    "class Deterministic(MonteCarloPredictor):\n",
    "    #V-table is initialized full of 0s\n",
    "    def follow_policy(self, observation, *args):\n",
    "        #if your cards add up to a number greater than 17, stand; otherwise, hit:\n",
    "        if observation[0] > 17:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6fffe-abb3-4e01-aa51-8ca3c96a869e",
   "metadata": {},
   "source": [
    "I set the ground for a parallel execution by defining two functions: the first one enqueues RL experiments and the second ones dequeues them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "121a08f0-bcad-4aa7-8ee1-0bfe6c91e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_q(q, episodes, show_every, save_every, collect_every):\n",
    "    \"\"\"\n",
    "    q: Queue from multiprocessing library\n",
    "    \"\"\"\n",
    "    sampler = Deterministic(env)\n",
    "    q.put(agents_methods[sampler.get_parent_class_str()](env, sampler, episodes, show_every, save_every, collect_every, train=False))\n",
    "    \n",
    "def get_q(q):\n",
    "    \"\"\"\n",
    "    q: Queue from multiprocessing library\n",
    "    \n",
    "    \"\"\"\n",
    "    return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053a0fd6-4683-4776-8e31-3b48fd279506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_sample_size_choice(sample_sizes, num_of_samples=10, number_of_runs=10):\n",
    "    \"\"\"\n",
    "    sample_sizes: a list of integers.\n",
    "    num_of_samples: an integer to indicate how many times rewards are averaged at\n",
    "                    each run. It helps simulate a bootstrapping process.\n",
    "    number_of_runs: number of times an experiment is repeated for each sample size.\n",
    "    \n",
    "    returns: a dictionary containing the reported stds and means for each run and sample size\n",
    "             dict[sample_size] = {stds: [std_run_1, std_run_2 ....],\n",
    "                                  means: [mean_run_1, mean_run_2 ....]\n",
    "                                  }\n",
    "    \"\"\"\n",
    "    summary = {}    \n",
    "    for sample_size in sample_sizes:\n",
    "        summary[sample_size] = {'stds': [],\n",
    "                                'means': [],\n",
    "                                }\n",
    "        # I use a server (Manager()) to allow the Queue to interact with different processes\n",
    "        queue = mp.Manager().Queue()\n",
    "        \n",
    "        EPISODES =  sample_size * num_of_samples\n",
    "        SHOW_EVERY = 1_000_000\n",
    "        SAVE_EVERY =  None\n",
    "        COLLECT_EVERY = sample_size\n",
    "        \n",
    "        # I enqueue every run\n",
    "        for _ in range(0, number_of_runs):\n",
    "            mp.Process(target=put_q, args=(queue, EPISODES, SHOW_EVERY, SAVE_EVERY, COLLECT_EVERY,)).start()\n",
    "\n",
    "        getter = []  \n",
    "        #I create a pool of workers to handle dequeuing and subsequent execution:\n",
    "        pool = mp.Pool(8)\n",
    "        for _ in range(0, number_of_runs):\n",
    "            getter.append(pool.apply_async(get_q, (queue,)))\n",
    "\n",
    "        #I extract results from every process and attach them to the dictionary:\n",
    "        for r in getter:\n",
    "            np_results = np.array(r.get())\n",
    "            summary[sample_size]['stds'].append(np_results.std())\n",
    "            summary[sample_size]['means'].append(np_results.mean())\n",
    "        \n",
    "    \n",
    "    return summary            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d846b-6003-4aad-8bae-b03ddac9b265",
   "metadata": {},
   "source": [
    "`This execution might take several minutes`\n",
    "1. I define some sample sizes.\n",
    "2. For each of them, I run 15 experiments.\n",
    "3. Ten average rewards are generated at each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3513434a-e562-40d8-88ea-8c85d9f18270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size_options=[100, 250, 500, 750, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "sample_size_summary = wrap_sample_size_choice(sample_size_options, number_of_runs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9c590-64e2-4418-a6fb-ad1bc666e4c7",
   "metadata": {},
   "source": [
    "I display the results in a boxplot fashion; The number of runs is small, so it is better to use a non-parametric method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "73b08c08-94eb-4c3d-bf4e-f1d00087da38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def box_plotting(summary):\n",
    "    stds = []\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    style_dict = {'xlabel': 'Sample size',\n",
    "                  'ylim': (0,0.2),\n",
    "                  'yticks': np.linspace(0, .2, 21),\n",
    "                  'yticklabels': np.linspace(0, .2, 21),\n",
    "                  'title': 'Dispersion and skewness of average rewards\\' standards '\n",
    "                           + 'deviation for different sample sizes'\n",
    "                 }\n",
    "    \n",
    "    ax = fig.add_subplot(1,1,1, **style_dict)\n",
    "    #unpacking stds:\n",
    "    for sample_size in summary:\n",
    "        stds.append(summary[sample_size]['stds'])\n",
    "        \n",
    "    ax.boxplot(stds, labels=summary.keys(),\n",
    "               positions=[i for i in range(0,len(summary))],\n",
    "               patch_artist=True,\n",
    "               medianprops={'color': 'red'},\n",
    "               sym= 'X')  \n",
    "    ax.grid()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "box_plotting(sample_size_summary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a922eb-b3c2-43c7-afbc-4ce745afb359",
   "metadata": {},
   "source": [
    "Given the above results, I will use a 8,000-reward sample size to average: median is near 0.01 std and upper whisker is around 0.015 std.\n",
    "\n",
    "Let's simulate bootstrapping in order to check whether or not we get a T-Student distribution (unknown population's std) for the average reward metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99b89e34-ac03-40be-9dd1-6967c04c7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_simulation(sample_size, num_of_samples=1_000, number_of_runs=10):\n",
    "    \"\"\"\n",
    "    sample_sizes: an integer.\n",
    "    num_of_samples: an integer to indicate how many times rewards are averaged at\n",
    "                    each run. It helps simulate a bootstrapping process.\n",
    "    number_of_runs: number of times an experiment is repeated for each sample size.\n",
    "    \n",
    "    returns: a dictionary containing the reported stds and means for each run and sample size\n",
    "             dict[sample_size] = {stds: [std_run_1, std_run_2 ....],\n",
    "                                  means: [mean_run_1, mean_run_2 ....]\n",
    "                                  }\n",
    "    \"\"\"\n",
    "    summary = {}    \n",
    "\n",
    "    summary[sample_size] = {'stds': [],\n",
    "                            'means': [],\n",
    "                           }\n",
    "    # I use a server (Manager()) to allow the Queue to interact with different processes\n",
    "    queue = mp.Manager().Queue()\n",
    "        \n",
    "    EPISODES =  sample_size * num_of_samples\n",
    "    SHOW_EVERY = 1_000_000\n",
    "    SAVE_EVERY =  None\n",
    "    COLLECT_EVERY = sample_size\n",
    "        \n",
    "    # I enqueue every run\n",
    "    for _ in range(0, number_of_runs):\n",
    "        mp.Process(target=put_q, args=(queue, EPISODES, SHOW_EVERY, SAVE_EVERY, COLLECT_EVERY,)).start()\n",
    "\n",
    "    getter = []  \n",
    "    #I create a pool of workers to handle dequeuing and subsequent execution:\n",
    "    pool = mp.Pool(8)\n",
    "    for _ in range(0, number_of_runs):\n",
    "        getter.append(pool.apply_async(get_q, (queue,)))\n",
    "\n",
    "    #I extract results from every process and attach them to the dictionary:\n",
    "    for r in getter:\n",
    "        np_results = np.array(r.get())\n",
    "        summary[sample_size]['stds'].append(np_results.std())\n",
    "        summary[sample_size]['means'].append(np_results.mean())\n",
    "        \n",
    "    \n",
    "    return summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
